{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Target Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Target Time Series File and Validation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "train_file_name = 'train.csv'\n",
    "train_data = pd.read_csv(os.path.join(data_dir,train_file_name))\n",
    "train_df = train_data.copy()\n",
    "train_df = train_df.rename(columns={'item':'item_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>store</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    item_id store  sales\n",
       "2013-01-01 00:00:00       1     1     13\n",
       "2013-01-02 00:00:00       1     1     11\n",
       "2013-01-03 00:00:00       1     1     14\n",
       "2013-01-04 00:00:00       1     1     13\n",
       "2013-01-05 00:00:00       1     1     10"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.set_index('date')\n",
    "train_df.store = train_df.store.astype(str)\n",
    "train_df.item_id = train_df.item_id.astype(str)\n",
    "train_df.index = pd.to_datetime(train_df.index, format = '%Y-%m-%d')\n",
    "train_df.index = train_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "cols_order = ['item_id', 'store','sales']\n",
    "train_df = train_df[cols_order]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>store</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-27 00:00:00</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28 00:00:00</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29 00:00:00</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30 00:00:00</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 00:00:00</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    item_id store  sales\n",
       "2017-12-27 00:00:00      50    10     63\n",
       "2017-12-28 00:00:00      50    10     59\n",
       "2017-12-29 00:00:00      50    10     74\n",
       "2017-12-30 00:00:00      50    10     62\n",
       "2017-12-31 00:00:00      50    10     82"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into target file and validation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-31 00:00:00\n",
      "2013-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(train_df.index.max())\n",
    "print(train_df.index.min())\n",
    "start_train_date = '2015-01-01' # Non-inclusive\n",
    "end_train_date = '2017-12-01' # Non-inclusive\n",
    "end_val_date = '2018-01-01' # Non-inclusive\n",
    "stores_sales = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_stores_sales = stores_sales[stores_sales.index >= start_train_date]\n",
    "target_stores_sales = target_stores_sales[target_stores_sales.index < end_train_date]\n",
    "validation_stores_sales = stores_sales[stores_sales.index >= end_train_date]\n",
    "validation_stores_sales = validation_stores_sales[validation_stores_sales.index < end_val_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 532500 entries, 2015-01-01 00:00:00 to 2017-11-30 00:00:00\n",
      "Data columns (total 3 columns):\n",
      "item_id    532500 non-null object\n",
      "store      532500 non-null object\n",
      "sales      532500 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "target_stores_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15500 entries, 2017-12-01 00:00:00 to 2017-12-31 00:00:00\n",
      "Data columns (total 3 columns):\n",
      "item_id    15500 non-null object\n",
      "store      15500 non-null object\n",
      "sales      15500 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 484.4+ KB\n"
     ]
    }
   ],
   "source": [
    "validation_stores_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the data in a great state, save it off as a CSV\n",
    "target_time_series_filename = \"target_time_series.csv\"\n",
    "target_time_series_path = data_dir + \"/\" + target_time_series_filename\n",
    "target_stores_sales.to_csv(target_time_series_path, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the data in a great state, save it off as a CSV\n",
    "validation_time_series_filename = \"validation_time_series.csv\"\n",
    "validation_time_series_path = data_dir + \"/\" + validation_time_series_filename\n",
    "validation_stores_sales.to_csv(validation_time_series_path, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FREQUENCY = \"D\" \n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "\n",
    "suffix = str(np.random.uniform())[4:9]\n",
    "\n",
    "\n",
    "# 원하는 프로젝트 이름을 넣으세요\n",
    "project = 'StoreItemDemand'\n",
    "target_suffix = '_target'\n",
    "\n",
    "\n",
    "target_datasetName= project+'DS' + suffix\n",
    "target_datasetGroupName= project +'DSG'+ suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-2\n"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "     data = json.load(notebook_info)\n",
    "     resource_arn = data['ResourceArn']\n",
    "     region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region)\n",
    "forecast = session.client(service_name='forecast')\n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the schema of your dataset here. Make sure the order of columns matches the raw data files.\n",
    "schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"store\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },       \n",
    "      {\n",
    "         \"AttributeName\":\"target_value\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Target Time Sereis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=forecast.create_dataset(\n",
    "                    Domain=\"CUSTOM\",\n",
    "                    DatasetType='TARGET_TIME_SERIES',\n",
    "                    DatasetName=target_datasetName,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    Schema = schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetArn': 'arn:aws:forecast:us-east-2:057716757052:dataset/StoreItemDemandDS47645',\n",
       " 'DatasetName': 'StoreItemDemandDS47645',\n",
       " 'Domain': 'CUSTOM',\n",
       " 'DatasetType': 'TARGET_TIME_SERIES',\n",
       " 'DataFrequency': 'D',\n",
       " 'Schema': {'Attributes': [{'AttributeName': 'timestamp',\n",
       "    'AttributeType': 'timestamp'},\n",
       "   {'AttributeName': 'item_id', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'store', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'target_value', 'AttributeType': 'float'}]},\n",
       " 'EncryptionConfig': {},\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2020, 3, 28, 7, 7, 48, 899000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 3, 28, 7, 7, 48, 899000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '5d96ca18-45d7-4819-82ce-cde38e995208',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sat, 28 Mar 2020 07:07:49 GMT',\n",
       "   'x-amzn-requestid': '5d96ca18-45d7-4819-82ce-cde38e995208',\n",
       "   'content-length': '556',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_datasetArn = response['DatasetArn']\n",
    "forecast.describe_dataset(DatasetArn=target_datasetArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create role\n",
    "Pleare uncomment if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use existing role\n",
    "role_arn = \"arn:aws:iam::057716757052:role/WalmartForecast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iam = boto3.client(\"iam\")\n",
    "\n",
    "# # 원하는 Role Name 을 넣으세요\n",
    "# # role_name = \"WalmartForecast\" + suffix\n",
    "# role_name = \"WalmartForecast\" \n",
    "# assume_role_policy_document = {\n",
    "#     \"Version\": \"2012-10-17\",\n",
    "#     \"Statement\": [\n",
    "#         {\n",
    "#           \"Effect\": \"Allow\",\n",
    "#           \"Principal\": {\n",
    "#             \"Service\": \"forecast.amazonaws.com\"\n",
    "#           },\n",
    "#           \"Action\": \"sts:AssumeRole\"\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# create_role_response = iam.create_role(\n",
    "#     RoleName = role_name,\n",
    "#     AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    "# )\n",
    "\n",
    "# # AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# # if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# # that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "# policy_arn = \"arn:aws:iam::aws:policy/AmazonForecastFullAccess\"\n",
    "# iam.attach_role_policy(\n",
    "#     RoleName = role_name,\n",
    "#     PolicyArn = policy_arn\n",
    "# )\n",
    "\n",
    "# # Now add S3 support\n",
    "# iam.attach_role_policy(\n",
    "#     PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "#     RoleName=role_name\n",
    "# )\n",
    "# time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "# role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "# print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bucket\n",
    "Uncomment the following code if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an existing bucket\n",
    "bucket_name = \"walmart-forecast\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(region)\n",
    "# s3 = boto3.client('s3')\n",
    "# account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "# # 원하는 버킷 이름을 넗으세요\n",
    "# # bucket_name = account_id + \"forecastpoc-gsmoon\"\n",
    "# # bucket_name = \"walmart-forecast\" + suffix\n",
    "# bucket_name = \"walmart-forecast\" \n",
    "# print(bucket_name)\n",
    "# if region != \"us-east-1\":\n",
    "#     s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
    "# else:\n",
    "#     s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset_import_job used to download dataset from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Target File\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(target_time_series_filename).upload_file(target_time_series_path)\n",
    "target_s3DataPath = \"s3://\"+bucket_name+\"/\"+target_time_series_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can call import the dataset\n",
    "datasetImportJobName = 'DSIMPORT_JOB_TARGET_WALMART' + suffix\n",
    "ds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=target_datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":target_s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:forecast:us-east-2:057716757052:dataset-import-job/StoreItemDemandDS47645/DSIMPORT_JOB_TARGET_WALMART47645\n"
     ]
    }
   ],
   "source": [
    "ds_target_import_job_arn=ds_import_job_response['DatasetImportJobArn']\n",
    "print(ds_target_import_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_PENDING\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "ACTIVE\n",
      "CPU times: user 37.1 ms, sys: 8.08 ms, total: 45.2 ms\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "while True:\n",
    "    dataImportStatus = forecast.describe_dataset_import_job(DatasetImportJobArn=ds_target_import_job_arn)['Status']\n",
    "    print(dataImportStatus)\n",
    "    if dataImportStatus != 'ACTIVE' and dataImportStatus != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data_dir' (str)\n",
      "Stored 'project' (str)\n",
      "Stored 'suffix' (str)\n",
      "Stored 'target_suffix' (str)\n",
      "Stored 'region' (str)\n",
      "Stored 'ds_target_import_job_arn' (str)\n",
      "Stored 'target_datasetArn' (str)\n",
      "Stored 'bucket_name' (str)\n",
      "Stored 'role_arn' (str)\n",
      "Stored 'validation_stores_sales' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store data_dir\n",
    "%store project\n",
    "%store suffix\n",
    "%store target_suffix\n",
    "%store region\n",
    "%store ds_target_import_job_arn\n",
    "%store target_datasetArn\n",
    "%store bucket_name\n",
    "%store role_arn\n",
    "%store validation_stores_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
