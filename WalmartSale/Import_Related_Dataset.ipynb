{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Related Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "train_file_name = 'train.csv'\n",
    "features_file_name = 'features.csv'\n",
    "store_file_name = 'stores.csv'\n",
    "feature_data = pd.read_csv(os.path.join(data_dir,features_file_name))\n",
    "feature_df = feature_data.copy()\n",
    "# Shift four dats in the future because of a basis of Monday in Forecast in uni of Weekly\n",
    "feature_df.Date = pd.to_datetime(feature_df['Date']) + pd.DateOffset(days=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = feature_df.drop(['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5'], axis=1)\n",
    "# Drop CPI, Unemployment because of missing values\n",
    "# Drop isHoliday because isHoliday exists in the built-in data of AWS Forecast\n",
    "feature_df = feature_df.drop(['CPI','Unemployment','IsHoliday'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-08 00:00:00</th>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-15 00:00:00</th>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-22 00:00:00</th>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01 00:00:00</th>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-08 00:00:00</th>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Temperature  Fuel_Price item_id\n",
       "2010-02-08 00:00:00        42.31       2.572       1\n",
       "2010-02-15 00:00:00        38.51       2.548       1\n",
       "2010-02-22 00:00:00        39.93       2.514       1\n",
       "2010-03-01 00:00:00        46.63       2.561       1\n",
       "2010-03-08 00:00:00        46.50       2.625       1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = feature_df.rename(columns={'Store':'item_id','Date':'date'})\n",
    "feature_df.reset_index(inplace=True)\n",
    "feature_df = feature_df.drop('index', axis=1)\n",
    "feature_df = feature_df.set_index('date')\n",
    "feature_df.item_id = feature_df.item_id.astype(str)\n",
    "feature_df.index = pd.to_datetime(feature_df.index, format = '%Y-%m-%d')\n",
    "feature_df.index = feature_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "cols = ['Temperature','Fuel_Price','item_id']\n",
    "feature_df = feature_df[cols]\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into target file and validation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_val_date = '2012-10-29'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_feature_df = feature_df[feature_df.index < end_val_date]\n",
    "#validation_stores_sales = stores_sales[stores_sales.index >= '2011-10-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the data in a great state, save it off as a CSV\n",
    "related_time_series_filename = \"related_time_series.csv\"\n",
    "related_time_series_path = data_dir + \"/\" + related_time_series_filename\n",
    "related_feature_df.to_csv(related_time_series_path, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FREQUENCY = \"W\" \n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "\n",
    "project = 'WalmartKaggle'\n",
    "related_suffix = '_related'\n",
    "\n",
    "related_dataset_Name= project+'DS' + related_suffix + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region)\n",
    "forecast = session.client(service_name='forecast')\n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the schema of your dataset here. Make sure the order of columns matches the raw data files.\n",
    "schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"Temperature\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"Fuel_Price\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      }       \n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Related Time Sereis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=forecast.create_dataset(\n",
    "                    Domain=\"CUSTOM\",\n",
    "                    DatasetType='RELATED_TIME_SERIES',\n",
    "                    DatasetName=related_dataset_Name,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    Schema = schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetArn': 'arn:aws:forecast:us-east-2:057716757052:dataset/WalmartKaggleDS_related38922',\n",
       " 'DatasetName': 'WalmartKaggleDS_related38922',\n",
       " 'Domain': 'CUSTOM',\n",
       " 'DatasetType': 'RELATED_TIME_SERIES',\n",
       " 'DataFrequency': 'W',\n",
       " 'Schema': {'Attributes': [{'AttributeName': 'timestamp',\n",
       "    'AttributeType': 'timestamp'},\n",
       "   {'AttributeName': 'Temperature', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'Fuel_Price', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'item_id', 'AttributeType': 'string'}]},\n",
       " 'EncryptionConfig': {},\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2020, 3, 26, 9, 49, 0, 627000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 3, 26, 9, 49, 0, 627000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'a3fce8d5-a713-4a4c-80cc-d39336e5f2a6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Thu, 26 Mar 2020 09:49:02 GMT',\n",
       "   'x-amzn-requestid': 'a3fce8d5-a713-4a4c-80cc-d39336e5f2a6',\n",
       "   'content-length': '572',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_datasetArn = response['DatasetArn']\n",
    "forecast.describe_dataset(DatasetArn=related_datasetArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset_import_job used to download dataset from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Target File\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(related_time_series_filename).upload_file(related_time_series_path)\n",
    "related_s3DataPath = \"s3://\"+bucket_name+\"/\"+related_time_series_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can call import the dataset\n",
    "datasetImportJobName = 'DSIMPORT_JOB_RELATED_WALMART' + related_suffix + suffix\n",
    "ds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=related_datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":related_s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:forecast:us-east-2:057716757052:dataset-import-job/WalmartKaggleDS_related38922/DSIMPORT_JOB_RELATED_WALMART_related38922\n"
     ]
    }
   ],
   "source": [
    "ds_related_import_job_arn=ds_import_job_response['DatasetImportJobArn']\n",
    "print(ds_related_import_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetImportJobName': 'DSIMPORT_JOB_RELATED_WALMART_related38922',\n",
       " 'DatasetImportJobArn': 'arn:aws:forecast:us-east-2:057716757052:dataset-import-job/WalmartKaggleDS_related38922/DSIMPORT_JOB_RELATED_WALMART_related38922',\n",
       " 'DatasetArn': 'arn:aws:forecast:us-east-2:057716757052:dataset/WalmartKaggleDS_related38922',\n",
       " 'TimestampFormat': 'yyyy-MM-dd hh:mm:ss',\n",
       " 'DataSource': {'S3Config': {'Path': 's3://walmart-forecast/related_time_series.csv',\n",
       "   'RoleArn': 'arn:aws:iam::057716757052:role/WalmartForecast'}},\n",
       " 'Status': 'CREATE_PENDING',\n",
       " 'CreationTime': datetime.datetime(2020, 3, 26, 9, 49, 8, 407000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 3, 26, 9, 49, 8, 407000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'a74e35ef-a840-4924-bf86-2c5bba36f77c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Thu, 26 Mar 2020 09:49:11 GMT',\n",
       "   'x-amzn-requestid': 'a74e35ef-a840-4924-bf86-2c5bba36f77c',\n",
       "   'content-length': '594',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.describe_dataset_import_job(DatasetImportJobArn=ds_related_import_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "ACTIVE\n",
      "CPU times: user 18.9 ms, sys: 1.18 ms, total: 20.1 ms\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "while True:\n",
    "    dataImportStatus = forecast.describe_dataset_import_job(DatasetImportJobArn=ds_related_import_job_arn)['Status']\n",
    "    print(dataImportStatus)\n",
    "    if dataImportStatus != 'ACTIVE' and dataImportStatus != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'related_suffix' (str)\n",
      "Stored 'ds_related_import_job_arn' (str)\n",
      "Stored 'related_datasetArn' (str)\n"
     ]
    }
   ],
   "source": [
    "%store related_suffix\n",
    "%store ds_related_import_job_arn\n",
    "%store related_datasetArn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
