{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 핸즈온 사전 단계 입니다.(This is a Prerequisite Step for later Contents)\n",
    "\n",
    "[핸즈온 준비 필수 단게: Prerequisite](Prerequisite.md)\n",
    "\n",
    "**Prerequisite Task: Make sure that a role for SageMaker notebook instance has these policies attached such as AmazonSageMakerFullAccess, AmazonS3FullAccess, AmazonForecastFullAccess, IAMFullAccess**\n",
    "\n",
    "# Forecasting Store Item Demanding with AWS Forecast  \n",
    "(Data Source: https://www.kaggle.com/c/demand-forecasting-kernels-only/overview)\n",
    "\n",
    "* **Description: Using AWS Forecast AI, forecasting the store item demanding problem (Daily Data)**\n",
    "\n",
    "* **Technique included**\n",
    "    * Use two dimenstions, item_id and store on Target Data\n",
    "    * Use QueryForecast with two filters, item_id and store\n",
    "    * Use QueryForecast with one filters, item_id \n",
    "    * Use HPO for building DeepARP \n",
    "    * Measure MAPE on Prophet and Deeparp campaigns    \n",
    "    * Compare Prophet and DeepARP performance with actual value\n",
    "\n",
    "\n",
    "* Process: (In the folder StoreItemDemand, run the following notebooks in order)\n",
    "    * 1.Prepare_Data_File.ipynb\n",
    "        * Prepare data file handling a raw data file\n",
    "    * 2.Import_Dataset.ipynb (About 10 mins elapsed)\n",
    "        * Create dataset group, dataset and dataset import job as well as importing the data file from S3\n",
    "        * The dataset file as target time series data has two dimensions such as item_id and store\n",
    "    * 3.Create_Target_Predictors.ipynb (About 40 mins elapsed)\n",
    "        * Create predictors with the prophet and deepar+ \n",
    "    * 4.Create_Target_Forecast.ipynb (About 50 mins elapsed)\n",
    "        * Create forecasts with the two predictors \n",
    "    * 5.Analyze_Target_Forecast.ipynb (About 10 mins elapsed)\n",
    "        * Analyze results on the forecasts\n",
    "    * 6.Cleanup.ipynb (About 10 mins elapsed)\n",
    "        * Clean up resources\n",
    "    * 7.Option_Create_Target_Predictors_HPO.ipynb (About 90 mins elapsed)\n",
    "        * Turning on HPO option, create  a predictor with deepar+ \n",
    "            \n",
    "\n",
    "# Forecasting Walmart Weekly Sale with AWS Forecast\n",
    "(Data Source: https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting)\n",
    "\n",
    "* **Description: Forecasting item's weekly sales in 45 U.S. Walmart stores with Amazon Forecast**\n",
    "\n",
    "* **Technique included**\n",
    "    * Use **three data sets of Target, Related and Item Meta**\n",
    "    * Compare Prophet and DeepARP performance with actual value    \n",
    "\n",
    "\n",
    "* Process: ( In the folder WalmartSale, run the following notebooks in order)\n",
    "    * **1. Only using target time series dataset**\n",
    "        * 0.LookAt_RawData.ipynb\n",
    "        * 1.1.Prepare_Target_Data_File.ipynb\n",
    "        * 1.2.Import_Dataset.ipynb\n",
    "            * Create dataset group, dataset, and make dataset import job\n",
    "        * 1.3.Create_Target_Predictors.ipynbe (About 40 mins elapsed)\n",
    "            * Use Prophet and Deepar+ algorithm\n",
    "        * 1.4.Create_Target_Forecast.ipynb (About 50 mins elapsed)\n",
    "        * 1.5.Analyze_Target_Forecast.ipynb (About 10 mins elapsed)\n",
    "            * Compute MAPE and show charts with p10,p50 and p90 as well as actual sales value\n",
    "        * 1.6.Cleanup.ipynb\n",
    "    * **2. Using target time series dataset plus related and item metadata dataset**\n",
    "        * 0.LookAt_RawData.ipynb    \n",
    "        * 2.0.Prepare_Target_Data_File.ipynb \n",
    "        * 2.1.Prepare_Related_Data_File.ipynb\n",
    "        * 2.2.Prepare_Item_Meta_Data_File.ipynb\n",
    "        * 2.3.Import_Target_Related_ItemMeta_Dataset.ipynb (About 5 mins elapsed)\n",
    "            * Create dataset group and target, related, and item meta dataset\n",
    "        * 2.4.Create_Target_Related_ItemMeta_Predictors.ipynb (About 40 mins elapsed)\n",
    "            * Use Prophet and Deepar+ algorithm\n",
    "        * 2.5.Create_Target_Related_ItemMeta_Forecast.ipynb (About 50 mins elapsed)\n",
    "        * 2.6.Analyze_Target_Related_ItemMeta_Forecast.ipynb (About 10 mins elapsed)\n",
    "            * Compute MAPE and show charts with p10,p50 and p90 as well as actual sales value        \n",
    "        * 2.7.Cleanup.ipynb\n",
    "\n",
    "    \n",
    "# Forecasting Traffic Volume with AWS Forecast\n",
    "**The following noteboos are based on the https://github.com/chrisking/ForecastPOC.git **\n",
    "\n",
    "* **Description: Forecasting traffic volume in interstate highway near Minneapolis city (AWS Forecast AI 서비스를 가지고 미국 미네라폴리스 근처 고속도로의 차량 통행량을 시간별로 예측하는 문제를 풀어가는 과정을 아래 4개의 노트북으로 구성 함.)**\n",
    "(Hourly Data)\n",
    "\n",
    "\n",
    "* **Technique included**\n",
    "    * Compare Target Data vs. Target + Related Data\n",
    "    * Compare ARIMA, Prophet and DeepARP performance with Acutal value\n",
    "\n",
    "\n",
    "* Process: (Traffic Volume 폴더 안에 노트북을 아래 순서대로 실행 하셔야 합니다.)\n",
    "    * Validating_and_Importing_Target_Time_Series_Data\n",
    "        * Prepare data and create Target Time Series Data\n",
    "    * Creating_and_Evaluating_Predictors\n",
    "        * With ARIMA, Prophet and DeepAR+, create Predictors and Forecasts\n",
    "    * Validating_and_Importing_Related_Time_Series_Data \n",
    "        * Create Related Time Series Data\n",
    "    * Creating_and_Evaluating_Related_Time_Predictors\n",
    "        * Using Target Time Series Data and Related Time Series Data, with Prophet and DeepAR+, create predictors and Forecasts\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
